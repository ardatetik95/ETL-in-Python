{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18f95100-8129-4b73-b841-a60dafdf5154",
   "metadata": {},
   "source": [
    "# Part 1 : Checking the data and defining Extract, Transform, Load steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acd64705-9627-4a13-be6f-bd18a482b9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging # Logging and the connected configuration will be used to pop up some messages to see if our extraction works well\n",
    "\n",
    "logging.basicConfig(format='%(levelname)s: %(message)s', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1fef468-637f-4c3a-a35c-1582f82731e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(file_path):\n",
    "    return pd.read_json(file_path) #Files are loaded in my personal computer, so I'll be using their path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4e566dbd-e02f-4fe8-84d9-aab0ce9dc09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16172 entries, 0 to 16171\n",
      "Data columns (total 23 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   ts                                 16172 non-null  object \n",
      " 1   platform                           16172 non-null  object \n",
      " 2   ms_played                          16172 non-null  int64  \n",
      " 3   conn_country                       16172 non-null  object \n",
      " 4   ip_addr                            16172 non-null  object \n",
      " 5   master_metadata_track_name         16170 non-null  object \n",
      " 6   master_metadata_album_artist_name  16170 non-null  object \n",
      " 7   master_metadata_album_album_name   16170 non-null  object \n",
      " 8   spotify_track_uri                  16170 non-null  object \n",
      " 9   episode_name                       2 non-null      object \n",
      " 10  episode_show_name                  2 non-null      object \n",
      " 11  spotify_episode_uri                2 non-null      object \n",
      " 12  audiobook_title                    0 non-null      float64\n",
      " 13  audiobook_uri                      0 non-null      float64\n",
      " 14  audiobook_chapter_uri              0 non-null      float64\n",
      " 15  audiobook_chapter_title            0 non-null      float64\n",
      " 16  reason_start                       16172 non-null  object \n",
      " 17  reason_end                         16172 non-null  object \n",
      " 18  shuffle                            16172 non-null  bool   \n",
      " 19  skipped                            16172 non-null  bool   \n",
      " 20  offline                            16172 non-null  bool   \n",
      " 21  offline_timestamp                  16172 non-null  int64  \n",
      " 22  incognito_mode                     16172 non-null  bool   \n",
      "dtypes: bool(4), float64(4), int64(2), object(13)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#Let's check the data before we start transforming it\n",
    "raw=pd.read_json(\"C:/Users/New PC 3/Desktop/Practice PR/Python 1.1 - Spotify ETL ELT test/stream_history/2023-2024.json\")\n",
    "raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65000160-5d16-4703-b509-979cbd426ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have some confidential information about country(conn_country) and ip address(ip_addr), both are also irrelevant to our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db029722-dd12-4c4a-aff3-d1106fcb8613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(raw_data):\n",
    "    #We start by handling time and date issues. Our current date is in object format. We have to transform it.\n",
    "    #Then we extract date and time information from it. \n",
    "\n",
    "        #Turning ts columns' data type from object to datetime\n",
    "    raw_data[\"ts\"]=pd.to_datetime(raw_data[\"ts\"])\n",
    "        #Extracting date and time information and creating new columns\n",
    "    raw_data[\"date\"]=raw_data[\"ts\"].dt.date\n",
    "    raw_data[\"time\"]=raw_data[\"ts\"].dt.time\n",
    "        #When we're done with ts column, we can drop it.\n",
    "    raw_data=raw_data.drop(\"ts\", axis=1)\n",
    "    \n",
    "    #Dropping some of the columns that include confidential information.\n",
    "    raw_data=raw_data.drop(['conn_country','ip_addr', 'spotify_track_uri'], axis=1)\n",
    "    \n",
    "    #Some of our columns have unpractically long names to use. We can alter them before we use them.\n",
    "        #Renaming columns\n",
    "    raw_data=raw_data.rename(columns={\"master_metadata_track_name\":\"track_name\", \"master_metadata_album_artist_name\":\"artist_name\", \n",
    "                                      \"master_metadata_album_album_name\":\"album_name\"})\n",
    "\n",
    "    #Our dataset holds both music and podcast information. We have to filter the relevant data, the music data first.\n",
    "        #Seperating podcast and song data\n",
    "    raw_data=raw_data[raw_data[\"episode_name\"].isnull()] # With this code, you can filter them by episode name being null.\n",
    "    # If you change isnull() part to notnull(), you can get podcast data as well. In this example, we'll be focusing on music data.\n",
    "\n",
    "    #Dropping the remaining uneccessary columns\n",
    "    raw_data=raw_data.drop(['episode_name', 'episode_show_name','spotify_episode_uri','audiobook_title', 'audiobook_uri','audiobook_chapter_uri', \n",
    "                            'audiobook_chapter_title','offline_timestamp', 'incognito_mode'], axis=1)\n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88a2b82c-eea5-4c81-99b2-d3fd844e726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to load our data into a csv file. \n",
    "def load(cleaned_music_data, file_path):\n",
    "    cleaned_music_data.to_csv(file_path, index=False)\n",
    "    print(f\"Successfully loaded data to {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5ab442f0-bf4c-405d-aefd-ebd50bd4020c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data to ETLtest.csv\n"
     ]
    }
   ],
   "source": [
    "# Now, we have all of the functions we need to run our ETL process\n",
    "raw_music_data=extract(\"C:/Users/New PC 3/Desktop/Practice PR/Python 1.1 - Spotify ETL ELT test/stream_history/2023-2024.json\")\n",
    "cleaned_music_data=transform(raw_music_data)\n",
    "load(cleaned_music_data, \"ETLtest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9764d2a9-f2a1-43dc-bafc-cd627ba716dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16170 entries, 0 to 16169\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   platform      16170 non-null  object\n",
      " 1   ms_played     16170 non-null  int64 \n",
      " 2   track_name    16170 non-null  object\n",
      " 3   artist_name   16170 non-null  object\n",
      " 4   album_name    16170 non-null  object\n",
      " 5   reason_start  16170 non-null  object\n",
      " 6   reason_end    16170 non-null  object\n",
      " 7   shuffle       16170 non-null  bool  \n",
      " 8   skipped       16170 non-null  bool  \n",
      " 9   offline       16170 non-null  bool  \n",
      " 10  date          16170 non-null  object\n",
      " 11  time          16170 non-null  object\n",
      "dtypes: bool(3), int64(1), object(8)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Let's check the dataset we got after the process\n",
    "data_check=pd.read_csv(\"ETLtest.csv\")\n",
    "data_check.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46073eea-246a-4eb3-8c9e-63be9e8a2d66",
   "metadata": {},
   "source": [
    "# Test 2 : ETL functioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9543ffda-32ab-4319-a43d-c5a83ba40a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 5 different files holding music data.\n",
    "# Logical way is to write another function that will take all the files, transform and get them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f33cd983-b933-4e76-a8d9-37dc41b74191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob #glob will help us to use the path names by catching patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fef30de8-4ac0-4e46-9efa-664b9c057c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ETL(files, load_file):\n",
    "    all_data = []\n",
    "\n",
    "    for file in files:\n",
    "        raw_data=extract(file)\n",
    "        clean_data=transform(raw_data)\n",
    "        all_data.append(clean_data) #We'll clean all the data and concat them into one single dataframe\n",
    "\n",
    "    combined_data=pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    load(combined_data, load_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2641b23e-97a8-41f8-ba11-b261266d495d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data to ETLplease.csv\n"
     ]
    }
   ],
   "source": [
    "#As all of our data is in a single file called stream_history, we can pass *.json to get all json files in that folder.\n",
    "json_files=glob.glob(\"C:/Users/New PC 3/Desktop/Practice PR/Python 1.1 - Spotify ETL ELT test/stream_history/*.json\")\n",
    "ETL(json_files, \"ETLplease.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ce95060-6d5d-4865-9f01-12630aed8989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65063 entries, 0 to 65062\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   platform      65063 non-null  object\n",
      " 1   ms_played     65063 non-null  int64 \n",
      " 2   track_name    65063 non-null  object\n",
      " 3   artist_name   65063 non-null  object\n",
      " 4   album_name    65063 non-null  object\n",
      " 5   reason_start  65063 non-null  object\n",
      " 6   reason_end    65063 non-null  object\n",
      " 7   shuffle       65063 non-null  bool  \n",
      " 8   skipped       65063 non-null  bool  \n",
      " 9   offline       65063 non-null  bool  \n",
      " 10  date          65063 non-null  object\n",
      " 11  time          65063 non-null  object\n",
      "dtypes: bool(3), int64(1), object(8)\n",
      "memory usage: 4.7+ MB\n"
     ]
    }
   ],
   "source": [
    "full=pd.read_csv(\"ETLplease.csv\")\n",
    "full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925f0381-6594-4693-b3dc-76f0bd323ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
